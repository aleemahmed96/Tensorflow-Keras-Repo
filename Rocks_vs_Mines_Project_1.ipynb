{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rocks vs Mines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "2AmnTbCWon4D",
        "rjW5aGjPD59T"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danidavid/Tensorflow-Keras-Repo/blob/master/Rocks_vs_Mines_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oMJYx7fURd81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Project 1: Rocks and Mines\n",
        "\n",
        "With the Grace of Allah, I have managed to complete the project. InshaAllah I will continue to make all projects in time.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "35LDeE3qvSPb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing dataset"
      ]
    },
    {
      "metadata": {
        "id": "3CAf6UX8I6ag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import io\n",
        "import requests\n",
        "\n",
        "#This will be used for online dataset import\n",
        "url='https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
        "\n",
        "s=requests.get(url).content\n",
        "\n",
        "c=pd.read_csv(io.StringIO(s.decode('UTF-8')),header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "egr8S7AZSfEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing library"
      ]
    },
    {
      "metadata": {
        "id": "QyltNz03I6ak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import io\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eV3aO7lJI6at",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "#dataframe=pd.read_csv('sonar.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LAU7vVshI6a2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#The following codes will run after R and M are converted to 0 and 1 respectively\n",
        "\n",
        "dataset=c.values\n",
        "X=dataset[:,0:60].astype(float) # [rows,colums] [also 0:60 signifies starting from 0 and ending till 60 variables in column]\n",
        "Y=dataset[:,60] # 60 in column to only copy R and M portion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hWYuIyD-OwRZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## For seed"
      ]
    },
    {
      "metadata": {
        "id": "mSRSudBlI6ao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fix random seed for reproducibility\n",
        "seed =7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDvrIEVII6bC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# To convert R and M into integer values 0 and 1"
      ]
    },
    {
      "metadata": {
        "id": "5mRqoEIfI6bF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I was trying to make a function but the problem was occuring as it was \n",
        "# numpy.ndarray and pandas is easy to change data values\n",
        "\n",
        "\n",
        "#def int_values(S,P):  \n",
        "#  if S in Y:\n",
        "#      dataset.loc[dataset[Y] == 'R',Y] = \"0\"\n",
        "#  if P in Y:\n",
        "#     dataset.loc[dataset[Y] == 'M', Y] = \"1\"\n",
        "# print(dataset)\n",
        "\n",
        "#int_values(\"R\",\"M\")\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Js64vc7dPXmL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Used LabelEncoder()\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Tqh5GVSmI6a7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Le= LabelEncoder()\n",
        "#Le.fit(Y)\n",
        "#encoded= Le.transform(Y)\n",
        "#encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQk1VC-EO8nQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Used .replace() function instead of LabelEncoder()\n",
        "\n",
        "LabelEncoder() does the same thing as the replace function, but LabelEncoder is implemented in multi label classification and also can be used here.\n",
        "\n",
        "I implemented it because it was easy to solve in one line. "
      ]
    },
    {
      "metadata": {
        "id": "KqsfPxFvI6bM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Converting with pandas by updating csv file into another csv file-name df\n",
        "#New csv file was made to be loaded from url\n",
        "df =c.replace([\"R\",\"M\"], [\"1\",\"0\"]) \n",
        "#using pandas as numpy was not able to change data easily\n",
        "#df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "27WzLEawI6bU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now using the code as indicated above\n",
        "dataset=df.values\n",
        "X=dataset[:,0:60].astype(float)\n",
        "Y=dataset[:,60].astype(int)\n",
        "encoded = Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "os2ydg6DPI0p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating Baseline model using Sequential API"
      ]
    },
    {
      "metadata": {
        "id": "JaFK5uhAI6bk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#baseline model\n",
        "def create_baseline():\n",
        "  #created model\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(20,activation='relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(20,activation='relu'))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  #compiled model\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zf4xj5c00xeE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Baseline model (Do not run the code again!)"
      ]
    },
    {
      "metadata": {
        "id": "3GhcgrXDu4CN",
        "colab_type": "code",
        "outputId": "1f5d4f4d-244c-4484-856e-551b257d031f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#evaluate model with standardized dataset\n",
        "estimator=[]\n",
        "estimator = KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(estimator,X,Y,cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" %(results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 82.21% (6.56%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x2iQ6Okjk0lZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running baseline model with data preparation (Do not run the code again!)"
      ]
    },
    {
      "metadata": {
        "id": "kIozbCBLlLj1",
        "colab_type": "code",
        "outputId": "9963f50b-9e25-4f4e-e350-d8a1fec8a2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Now with Pipeline() and StandardScalar()\n",
        "import numpy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "numpy.random.seed(seed)\n",
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: 84.11% (8.36%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s8d-WH62zshL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now with smaller network"
      ]
    },
    {
      "metadata": {
        "id": "7Hv3ZUeHkaHX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For create_smaller3()"
      ]
    },
    {
      "metadata": {
        "id": "C3GMYA36zUKz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#smaller model\n",
        "def create_smaller3():\n",
        "  #created model\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(30,activation='relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(20,activation='relu'))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  #compiled model\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhtfcyLkzraC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller3,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6n6JDKsDNMuz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For create_smaller9()"
      ]
    },
    {
      "metadata": {
        "id": "4d9bMUpm70nU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#smaller model\n",
        "def create_smaller9():\n",
        "  #created model\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(30,activation='relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(15,activation='relu'))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  #compiled model\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PQR4qE574Ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller9,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWHe3qfoev4_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### changing n_splits=9"
      ]
    },
    {
      "metadata": {
        "id": "8fcDVK6rNFL6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller9,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=9,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ApXaVAnFes-r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### changing n_splits=5"
      ]
    },
    {
      "metadata": {
        "id": "mb5emKMKWQX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller9,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iUhU-HRfnWCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now with larger network"
      ]
    },
    {
      "metadata": {
        "id": "OtWiRI0vfFw1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Larger Model\n",
        "def create_larger():\n",
        "  #create model\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Dense(60,activation='relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(30,activation='relu'))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  #compiled model\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4RsV2jVne0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_larger,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AmnTbCWon4D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Developing a model that overfits\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RM24gOXdormv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#overfitting model\n",
        "def create_overfit():\n",
        "  #create model\n",
        "  model = keras.Sequential()\n",
        "  #adding more layers & making them bigger\n",
        "  model.add(layers.Dense(60,activation='relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(50,activation='relu'))\n",
        "  model.add(layers.Dense(60,activation='relu'))\n",
        "  model.add(layers.Dense(50,activation='relu'))\n",
        "  model.add(layers.Dense(40,activation='relu'))\n",
        "  model.add(layers.Dense(30,activation='relu'))\n",
        "  model.add(layers.Dense(20,activation='relu'))\n",
        "  model.add(layers.Dense(10,activation='relu'))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  #compiled model\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  #training for more epochs\n",
        "  model.fit(X,Y,epochs=100,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jC8BY9ej2h48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_overfit,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Overfit: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "okhqqZKb_qcf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tuning the model"
      ]
    },
    {
      "metadata": {
        "id": "Pb0ec4WN_zoQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_tuner():\n",
        "  #create model\n",
        "  model = keras.Sequential()\n",
        "  #adding more layers & making them bigger\n",
        "  model.add(layers.Dense(60,activation='relu',input_shape=(60,)))\n",
        "  model.add(layers.Dense(50,activation='relu'))\n",
        "  model.add(layers.Dense(60,activation='relu'))\n",
        "  model.add(layers.Dense(50,activation='relu'))\n",
        "  model.add(layers.Dense(40,activation='relu'))\n",
        "  model.add(layers.Dense(30,activation='relu'))\n",
        "  model.add(layers.Dense(20,activation='relu'))\n",
        "  model.add(layers.Dense(10,activation='relu'))\n",
        "  model.add(layers.Dense(1,activation='sigmoid'))\n",
        "  #compiled model\n",
        "  model.compile(optimizer='Adamax',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  #training for more epochs\n",
        "  model.fit(X,Y,epochs=200,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zcKdMi-5_-lH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimator=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_overfit,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Tuned: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8bCrmX-mBiUf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The best score achieved in this dataset is in the below link \n",
        "https://colab.research.google.com/drive/1zs6Hx_po7PeQgzS5kjN8wx6g2gB7jhFf#scrollTo=zcKdMi-5_-lH&line=7&uniqifier=1\n",
        "\n",
        "### The dataset achieved\n",
        "Tuned: 89.34% (4.83%)"
      ]
    },
    {
      "metadata": {
        "id": "rjW5aGjPD59T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Rewriting the code using Keras functional API"
      ]
    },
    {
      "metadata": {
        "id": "WP9pJYFvK2QJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating baseline model"
      ]
    },
    {
      "metadata": {
        "id": "xBCXNIINEEQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating baseline model\n",
        "def kf_baseline():\n",
        "  #create model\n",
        "  input = keras.Input(shape=(60,))\n",
        "  a = layers.Dense(20,activation='relu')(input)\n",
        "  a = layers.Dense(20,activation='relu')(a)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(a)\n",
        "  #compile model\n",
        "  model = keras.Model(input, outputs)\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "va-PRGeaFD0-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#evaluate model with standardized dataset\n",
        "estimator=[]\n",
        "estimator = KerasClassifier(build_fn=kf_baseline,epochs=100,batch_size=5,verbose=0)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(estimator,X,Y,cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" %(results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEUSRpTOK-Pv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running baseline model with data preparation"
      ]
    },
    {
      "metadata": {
        "id": "JeZxSwehLHmv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now with Pipeline() and StandardScalar()\n",
        "import numpy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "numpy.random.seed(seed)\n",
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=kf_baseline,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aOCBfOSPrGq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now with smaller network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D3z34F57P--0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#smaller model \n",
        "def create_kfsmaller():  \n",
        "  #create model\n",
        "  input = keras.Input(shape=(60,))\n",
        "  a = layers.Dense(30,activation='relu')(input)\n",
        "  a = layers.Dense(15,activation='relu')(a)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(a)\n",
        "  #compile model\n",
        "  model = keras.Model(input, outputs)\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICH2HHM6PwwA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_kfsmaller,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBDWr9gWSSrT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now with larger network"
      ]
    },
    {
      "metadata": {
        "id": "iIbmEn-XR33e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#larger model \n",
        "def create_kflarger():  \n",
        "  #create model\n",
        "  input = keras.Input(shape=(60,))\n",
        "  a = layers.Dense(60,activation='relu')(input)\n",
        "  a = layers.Dense(30,activation='relu')(a)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(a)\n",
        "  #compile model\n",
        "  model = keras.Model(input, outputs)\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSynPQNgSRv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_kflarger,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3fOKf2WU3Xd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Developing a model that overfits"
      ]
    },
    {
      "metadata": {
        "id": "orBddnRiU5Ay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#overfit model \n",
        "def create_kfoverfit():  \n",
        "  #create model\n",
        "  input = keras.Input(shape=(60,))\n",
        "  a = layers.Dense(60,activation='relu')(input)\n",
        "  a = layers.Dense(60,activation='relu')(a)\n",
        "  a = layers.Dense(50,activation='relu')(a)\n",
        "  a = layers.Dense(60,activation='relu')(a)\n",
        "  a = layers.Dense(50,activation='relu')(a)\n",
        "  a = layers.Dense(40,activation='relu')(a)\n",
        "  a = layers.Dense(30,activation='relu')(a)\n",
        "  a = layers.Dense(20,activation='relu')(a)\n",
        "  a = layers.Dense(10,activation='relu')(a)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(a)\n",
        "  #compile model\n",
        "  model = keras.Model(input, outputs)\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=20,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pDfBVgMGVDJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_kfoverfit,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Overfit: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhZxlpkGXUW1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tuning the model"
      ]
    },
    {
      "metadata": {
        "id": "ac_c16TlXcz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tuning model \n",
        "def create_kftune():  \n",
        "  #create model\n",
        "  input = keras.Input(shape=(60,))\n",
        "  a = layers.Dense(60,activation='relu')(input)\n",
        "  a = layers.Dense(60,activation='relu')(a)\n",
        "  a = layers.Dense(50,activation='relu')(a)\n",
        "  a = layers.Dense(60,activation='relu')(a)\n",
        "  a = layers.Dense(50,activation='relu')(a)\n",
        "  a = layers.Dense(40,activation='relu')(a)\n",
        "  a = layers.Dense(30,activation='relu')(a)\n",
        "  a = layers.Dense(20,activation='relu')(a)\n",
        "  a = layers.Dense(10,activation='relu')(a)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(a)\n",
        "  #compile model\n",
        "  model = keras.Model(input, outputs)\n",
        "  model.compile(optimizer='Adamax',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=200,batch_size=32)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3VHJ5ID3XYGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_kftune,epochs=100,batch_size=5,verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=seed)\n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Tuned: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4A0FWI-9eTOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimators=[]\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_kftune,epochs=200,batch_size=5,verbose=0))) #epochs are changed to 200\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=9,shuffle=True,random_state=seed) # n_splits cahnged to 9 (just experimenting) \n",
        "results = cross_val_score(pipeline,X,Y,cv=kfold)\n",
        "print(\"Tuned: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RW0Gjmbfk8vu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Rewriting the code using Model Subclassing"
      ]
    },
    {
      "metadata": {
        "id": "ErqPDwc2rrKQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating baseline model"
      ]
    },
    {
      "metadata": {
        "id": "yIDidq0xHA9C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input = keras.Input(shape=(60,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D969F9Mxk_pH",
        "colab_type": "code",
        "outputId": "431a7a7f-b34d-4e6f-d465-d02895e622fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "#making a class\n",
        "class MyModel(keras.Model):\n",
        "    \n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense1 = layers.Dense(60,activation='relu')\n",
        "    self.dense2 = layers.Dense(20,activation='relu')\n",
        "    self.dense3 = layers.Dense(20,activation='relu')\n",
        "    self.dense4 = layers.Dense(1,activation='softmax')\n",
        "    \n",
        "  def call(self,inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    x = self.dense3(x)\n",
        "    return self.dense4(x)\n",
        "  \n",
        "model = MyModel()\n",
        "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X,Y,epochs=20,batch_size=32)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "208/208 [==============================] - 2s 9ms/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 2/20\n",
            "208/208 [==============================] - 0s 94us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 3/20\n",
            "208/208 [==============================] - 0s 88us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 4/20\n",
            "208/208 [==============================] - 0s 84us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 5/20\n",
            "208/208 [==============================] - 0s 85us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 6/20\n",
            "208/208 [==============================] - 0s 97us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 7/20\n",
            "208/208 [==============================] - 0s 103us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 8/20\n",
            "208/208 [==============================] - 0s 111us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 9/20\n",
            "208/208 [==============================] - 0s 92us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 10/20\n",
            "208/208 [==============================] - 0s 103us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 11/20\n",
            "208/208 [==============================] - 0s 104us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 12/20\n",
            "208/208 [==============================] - 0s 98us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 13/20\n",
            "208/208 [==============================] - 0s 98us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 14/20\n",
            "208/208 [==============================] - 0s 102us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 15/20\n",
            "208/208 [==============================] - 0s 99us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 16/20\n",
            "208/208 [==============================] - 0s 109us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 17/20\n",
            "208/208 [==============================] - 0s 109us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 18/20\n",
            "208/208 [==============================] - 0s 93us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 19/20\n",
            "208/208 [==============================] - 0s 85us/step - loss: 8.5077 - acc: 0.4663\n",
            "Epoch 20/20\n",
            "208/208 [==============================] - 0s 90us/step - loss: 8.5077 - acc: 0.4663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2924d34b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "o529TMzOLekV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Making model without using scikit-learn"
      ]
    },
    {
      "metadata": {
        "id": "WsuMlxErl8Wz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_baseline():\n",
        "  #create model\n",
        "  input = keras.Input(shape=(60,))\n",
        "  a = layers.Dense(20,activation='relu')(input)\n",
        "  a = layers.Dense(20,activation='relu')(a)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(a)\n",
        "  #compile model\n",
        "  model = keras.Model(input, outputs)\n",
        "  model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  model.fit(X,Y,epochs=200,batch_size=32,verbose=0)\n",
        "  return model\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPqczKKRQ6Uw",
        "colab_type": "code",
        "outputId": "62d3d76c-8761-4507-fc61-d3b5e19a0a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "k = 4\n",
        "num_val_samples = len(X) // k\n",
        "num_epochs = 600\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = encoded[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate([X[:i * num_val_samples],X[(i + 1) * num_val_samples:]],axis=0)\n",
        "    partial_train_targets = np.concatenate([encoded[:i * num_val_samples],encoded[(i + 1) * num_val_samples:]],axis=0)\n",
        "model = create_baseline()\n",
        "model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=32, verbose=0)\n",
        "val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "all_scores.append(val_mae)\n",
        "\n",
        "score = np.average(all_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ef66302e98bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YopZZSbc4oeW",
        "colab_type": "code",
        "outputId": "61bc9807-836f-40ba-ab4d-6137547e29f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Result: %.2f%% (%.2f%%)\" % (score.mean()*100,score.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: 71.15% (0.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hw3-6R5n5eS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Another way of doing it will be posted soon..."
      ]
    }
  ]
}